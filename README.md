# ğŸ“ KinAI-Mentor

<div align="center">

### *Open-Source, Offline Educational Assistant Powered by Local LLM*

---

[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)](https://streamlit.io)
[![Ollama](https://img.shields.io/badge/Ollama-000000?style=for-the-badge&logo=ollama&logoColor=white)](https://ollama.ai)
[![MIT License](https://img.shields.io/badge/License-MIT-00C851?style=for-the-badge)](LICENSE)
[![100% Offline](https://img.shields.io/badge/100%25-OFFLINE-9C27B0?style=for-the-badge)](https://github.com)

**ğŸŒŸ A 100% offline, open-source, voice-driven tutor that's free, flexible, and aligned with the Victorian Curriculum Fâ€“10 Version 2.0 ğŸŒŸ**
<p align="center">
  <img src="https://raw.githubusercontent.com/Logulokesh/KinAI-Mentor/refs/heads/main/screenshots/Logo-4.gif" alt="KinAi-Nexpatrol" width="100%" />
</p>
</div>

---

## ğŸš€ **The Vision**

<!-- Row 1: Identify the Challenge --> <table style="width: 100%; border-collapse: collapse; font-family: sans-serif;"> <tr> <td style="width: 500px; text-align: center; vertical-align: top; padding: 80px;"> <img src="identify.png" width="220" alt="Identify" /> </td> <td style="padding: 40px; vertical-align: top;"> <h2 style="color: #2563eb; display: flex; align-items: center; gap: 10px; margin-top: 0;"> <span style="font-size: 24px;">ğŸ”</span> 1. Identify the Challenge </h2> <p> Modern education lacks personalized support due to time and resource limits. KinAI-Mentor solves this with an <strong>offline ğŸŒ, open-source ğŸ¤– AI tutor</strong>, aligned with the <strong>Victorian Curriculum Fâ€“10 Version 2.0 ğŸ“</strong>, offering accessible, flexible learning for all students ğŸ¯. </p> </td> </tr> </table> <!-- Row 2: Engineer the Approach --> <table style="width: 100%; border-collapse: collapse; font-family: sans-serif; background-color: #f9f9f9;"> <tr> <td style="padding: 40px; vertical-align: top;"> <h2 style="color: #16a34a; display: flex; align-items: center; gap: 10px; margin-top: 0;"> <span style="font-size: 24px;">âš™ï¸</span> 2. Engineer the Approach </h2> <p> KinAI-Mentor uses a <strong>local LLM ğŸ§  via Ollama</strong> for real-time responses without internet ğŸŒ. It combines <strong>speech-to-text ğŸ™ï¸</strong> and <strong>text-to-speech ğŸ”Š AI</strong> for hands-free interaction ğŸ’¬. </p> <p> Fully offline, it ensures <strong>privacy ğŸ”’</strong>, <strong>speed âš¡</strong>, and <strong>customizability</strong>, supporting both voice and text input/output ğŸ“±. </p> </td> <td style="width: 220px; text-align: center; vertical-align: top; padding: 40px;"> <img src="support.png" width="220" alt="Support" /> </td> </tr> </table> <!-- Row 3: Implement the Outcome --> <table style="width: 100%; border-collapse: collapse; font-family: sans-serif;"> <tr> <td style="width: 220px; text-align: center; vertical-align: top; padding: 40px;"> <img src="empower.png" width="220" alt="Empower" /> </td> <td style="padding: 40px; vertical-align: top;"> <h2 style="color: #dc2626; display: flex; align-items: center; gap: 10px; margin-top: 0;"> <span style="font-size: 24px;">âœ…</span> 3. Implement the Outcome </h2> <p> A fully functional, <strong>AI-driven tutoring system ğŸš€</strong> that runs locally on any device ğŸ“±. Students learn at their own pace using <strong>voice commands ğŸ™ï¸</strong> or <strong>chat input ğŸ’¬</strong>. </p> <p> Built with <strong>on-device AI</strong>, it supports diverse learners â™¿â€”ideal for those with disabilities or limited digital access. An empowering, joyful step forward in education ğŸ‰. </p> </td> </tr> </table>

**ğŸ’¬ Interactive** â€¢ **ğŸ“± Cross-Platform** â€¢ **â™¿ Accessible** â€¢ **ğŸš€ Performance** â€¢ **ğŸ‰ Engaging**

</div>

---

## ğŸŒŸ **Overview**

> **Why KinAI-Mentor?** While tech giants focus on enterprise AI tools, we're solving something fundamental: helping kids learn when life gets busy. 

**KinAI-Mentor** isn't just another educational appâ€”it's a **100% offline, open-source, voice-driven tutor** that's:
- ğŸ†“ **Completely Free** - No subscriptions, no hidden costs
- ğŸ”§ **Fully Customizable** - Open-source and hackable
- ğŸ“š **Curriculum-Aligned** - Victorian Curriculum Fâ€“10 Version 2.0
- ğŸ¤ **Voice & Text Ready** - Multiple interaction modes

---

## â­ **Key Features**

<div align="center">

| ğŸ¤ **Voice Input** | ğŸ’¬ **Chat Input** | ğŸ—£ï¸ **Voice Output** | ğŸ“ƒ **Text Display** |
|:---:|:---:|:---:|:---:|
| Speak your questions naturally | Type queries traditionally | Answers read aloud via TTS | Visual responses on screen |

| ğŸ“ **Curriculum-Aligned** | ğŸ’» **100% Offline** | ğŸ› ï¸ **Open-Source** | ğŸ”Š **Multilingual** |
|:---:|:---:|:---:|:---:|
| Victorian Curriculum Fâ€“10 V2.0 | No internet dependency | Free to modify & extend | Optional language models |

</div>

---

## ğŸ—ï¸ **System Architecture**

```mermaid
graph TB
    subgraph "ğŸ¯ User Interaction"
        A[ğŸ‘¤ User]
        A -->|ğŸ¤ Voice| B[Microphone]
        A -->|ğŸ’¬ Text| C[Text Input]
    end
    
    subgraph "ğŸ”„ Input Processing"
        B --> D[ğŸ§ Speech-to-Text]
        C --> E[âš™ï¸ Query Processor]
        D --> E
    end
    
    subgraph "ğŸ§  AI Core"
        E --> F[ğŸ¤– Ollama LLM]
        F <--> G[ğŸ’¾ Knowledge Base]
        F <--> H[ğŸ“š Curriculum Data]
    end
    
    subgraph "ğŸ“¤ Output Generation"
        F --> I[ğŸ”§ Response Formatter]
        I --> J[ğŸ–¥ï¸ Text Display]
        I --> K[ğŸ”Š Text-to-Speech]
        K --> L[ğŸ¶ Audio Output]
    end
    
    J --> A
    L --> A
    
    style A fill:#e1f5fe
    style F fill:#f3e5f5
    style G fill:#e8f5e8
    style H fill:#fff3e0
```

### ğŸ“‹ **How It Works**

<details>
<summary><b>ğŸ” Click to expand architecture details</b></summary>

| Component | Function | Technology |
|-----------|----------|------------|
| **ğŸ‘¤ User Interface** | Voice/text input handling | Streamlit + Speech Recognition |
| **ğŸ§ Speech Processing** | Voice-to-text conversion | Offline speech recognition |
| **ğŸ§  AI Engine** | Query processing & responses | Ollama LLM (local) |
| **ğŸ’¾ Knowledge Base** | General learning content | JSON database |
| **ğŸ“š Curriculum** | Victorian Curriculum alignment | Structured JSON |
| **ğŸ”Š Audio Output** | Text-to-speech synthesis | Local TTS engine |

</details>

---

## ğŸ¯ **Why Choose KinAI-Mentor?**

<div align="center">

| **ğŸŒŸ Benefit** | **ğŸ”¥ Why It Matters** |
|:---|:---|
| **â™¿ Accessible Design** | Supports auditory, visual, and diverse learners |
| **ğŸ§  Curriculum-Focused** | Aligned with Victorian Curriculum Fâ€“10 V2.0 |
| **ğŸ” Multi-Modal** | Seamless voice â†” text switching |
| **ğŸ“± Hands-Free Learning** | Perfect for multitasking or accessibility needs |
| **ğŸŒ Privacy-First** | 100% offline - your data never leaves your device |
| **ğŸ”§ Developer-Friendly** | Open-source, customizable, and extensible |
| **âš¡ No Dependencies** | Works without internet, subscriptions, or accounts |

</div>

---

## ğŸ› ï¸ **Quick Start**

### ğŸ“‹ **Prerequisites**

<div align="center">

| Requirement | Version | Purpose |
|:---:|:---:|:---:|
| ğŸ **Python** | 3.8+ | Core runtime |
| ğŸ¤– **Ollama** | Latest | Local LLM |
| ğŸ¤ **Microphone** | Any | Voice input |
| ğŸ”Š **Audio Output** | Any | Voice responses |

</div>

### âš¡ **Installation**

```bash
# 1ï¸âƒ£ Clone the repository
git clone https://github.com/Logulokesh/kinai-mentor.git
cd kinai-mentor

# 2ï¸âƒ£ Create virtual environment
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

# 4ï¸âƒ£ Setup Ollama
# Download from https://ollama.ai
ollama pull llama3

# 5ï¸âƒ£ Launch KinAI-Mentor
streamlit run ui.py
```

### ğŸš€ **Launch Commands**

```bash
# Start Ollama server
ollama run llama3

# Launch KinAI-Mentor interface
streamlit run ui.py
```

---

## ğŸ“ **Project Structure**

<div align="center">

| File | Purpose | Icon |
|:---|:---|:---:|
| `core_tutor.py` | Core AI logic & processing | âš™ï¸ |
| `ui.py` | Streamlit user interface | ğŸ–¥ï¸ |
| `syllabus.json` | Victorian Curriculum data | ğŸ“š |
| `voicetutor_db.json` | Knowledge base | ğŸ“‚ |
| `requirements.txt` | Python dependencies | ğŸ“‹ |
| `README.md` | Documentation | ğŸ“– |

</div>

---

## ğŸ› ï¸ **Tech Stack**

<div align="center">

### **Core Technologies**

[![Python](https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=blue)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)](https://streamlit.io)
[![Ollama](https://img.shields.io/badge/Ollama-000000?style=for-the-badge&logo=ollama&logoColor=white)](https://ollama.ai)

### **AI & Audio**

![Speech Recognition](https://img.shields.io/badge/Speech_Recognition-00D4AA?style=for-the-badge&logo=google&logoColor=white)
![Text to Speech](https://img.shields.io/badge/Text_to_Speech-4285F4?style=for-the-badge&logo=google&logoColor=white)
![JSON](https://img.shields.io/badge/JSON-000000?style=for-the-badge&logo=json&logoColor=white)

</div>

---

## ğŸ¤ **Contributing**

<div align="center">

**ğŸŒŸ Help us make learning more accessible! ğŸŒŸ**

[![Contribute](https://img.shields.io/badge/Contribute-Welcome-brightgreen?style=for-the-badge)](CONTRIBUTING.md)
[![Issues](https://img.shields.io/badge/Issues-Open-red?style=for-the-badge)](https://github.com/Logulokesh/kinai-mentor/issues)
[![PRs](https://img.shields.io/badge/PRs-Welcome-blue?style=for-the-badge)](https://github.com/Logulokesh/kinai-mentor/pulls)

</div>

### ğŸ”§ **How to Contribute**

1. ğŸ´ **Fork** the repository
2. ğŸŒ¿ **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. âœ… **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. ğŸš€ **Push** to the branch (`git push origin feature/amazing-feature`)
5. ğŸ“¬ **Open** a Pull Request

---

## ğŸ“œ **License**

<div align="center">

[![MIT License](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)

**Free to use, modify, and distribute under the MIT License**

</div>

---

## ğŸ“¸ **Screenshots**

<div align="center">

### ğŸ–¥ï¸ **Main Interface**
*Clean, intuitive design for seamless learning*

![KinAI-Mentor Main Interface](https://raw.githubusercontent.com/Logulokesh/VICTutorAI-Offline-Educational-Assistant-Voice/refs/heads/main/screenshots/001%20-%20VoiceTutor%20Online%20Classroom%20-%20%5Blocalhost%5D.png)

---

### ğŸ’¬ **Interactive Learning**
*Real-time conversations with AI tutor*

![Interactive Learning](https://raw.githubusercontent.com/Logulokesh/VICTutorAI-Offline-Educational-Assistant-Voice/refs/heads/main/screenshots/002%20-%20VoiceTutor%20Online%20Classroom%20-%20%5Blocalhost%5D.png)

---

### ğŸ¤ **Voice Interaction**
*Hands-free learning experience*

![Voice Interaction](https://raw.githubusercontent.com/Logulokesh/VICTutorAI-Offline-Educational-Assistant-Voice/refs/heads/main/screenshots/003%20-%20VoiceTutor%20Online%20Classroom%20-%20%5Blocalhost%5D.png)

---

### ğŸ“š **Curriculum Content**
*Victorian Curriculum Fâ€“10 Version 2.0 aligned*

![Curriculum Content](https://raw.githubusercontent.com/Logulokesh/VICTutorAI-Offline-Educational-Assistant-Voice/refs/heads/main/screenshots/005%20-%20VoiceTutor%20Online%20Classroom%20-%20%5Blocalhost%5D.png)

---

### ğŸ¯ **Learning Dashboard**
*Track progress and engagement*

![Learning Dashboard](https://raw.githubusercontent.com/Logulokesh/VICTutorAI-Offline-Educational-Assistant-Voice/refs/heads/main/screenshots/006%20-%20VoiceTutor%20Online%20Classroom%20-%20%5Blocalhost%5D.png)

</div>

---

**Made with â¤ï¸ for accessible education**

---

*KinAI-Mentor - Empowering learners through intelligent, offline AI tutoring*

</div>
