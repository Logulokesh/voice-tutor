<div align="center">

# ğŸ“âš¡ KinAI-Mentor - AI Educational Assistant
*Next-Gen Offline Learning & Intelligent Tutoring*

**[ ğŸ¤– AI-POWERED ] â€¢ [ ğŸ¤ VOICE-DRIVEN ] â€¢ [ ğŸ”’ PRIVACY-FIRST ]**

![Python](https://img.shields.io/badge/Python-3776ab?style=for-the-badge&logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![Ollama](https://img.shields.io/badge/Ollama-000000?style=for-the-badge&logo=ollama&logoColor=white)
![Offline](https://img.shields.io/badge/100%25_OFFLINE-9C27B0?style=for-the-badge&logo=offline&logoColor=white)

<p align="center">
  <img src="https://raw.githubusercontent.com/Logulokesh/KinAI-Mentor/refs/heads/main/screenshots/Logo-4.gif" alt="KinAi-Mentor" width="100%" />
</p>

<p align="center">
  <strong>ğŸ§  Local LLM â€¢ ğŸ¯ Victorian Curriculum â€¢ ğŸ”„ Speech Recognition â€¢ ğŸ Open Source</strong>
</p>

---

*Transform education with cutting-edge AI that listens, teaches, and empowers*

</div>


---

## ğŸš€ **The Vision**

<!-- Row 1: Identify the Challenge --> <table style="width: 100%; border-collapse: collapse; font-family: sans-serif;"> <tr> <td style="width: 500px; text-align: center; vertical-align: top; padding: 80px;"> <img src="identify.png" width="220" alt="Identify" /> </td> <td style="padding: 40px; vertical-align: top;"> <h2 style="color: #2563eb; display: flex; align-items: center; gap: 10px; margin-top: 0;"> <span style="font-size: 24px;">ğŸ”</span> 1. Identify the Challenge </h2> <p> Modern education lacks personalized support due to time and resource limits. KinAI-Mentor solves this with an <strong>offline ğŸŒ, open-source ğŸ¤– AI tutor</strong>, aligned with the <strong>Victorian Curriculum Fâ€“10 Version 2.0 ğŸ“</strong>, offering accessible, flexible learning for all students ğŸ¯. </p> </td> </tr> </table> <!-- Row 2: Engineer the Approach --> <table style="width: 100%; border-collapse: collapse; font-family: sans-serif; background-color: #f9f9f9;"> <tr> <td style="padding: 40px; vertical-align: top;"> <h2 style="color: #16a34a; display: flex; align-items: center; gap: 10px; margin-top: 0;"> <span style="font-size: 24px;">âš™ï¸</span> 2. Engineer the Approach </h2> <p> KinAI-Mentor uses a <strong>local LLM ğŸ§  via Ollama</strong> for real-time responses without internet ğŸŒ. It combines <strong>speech-to-text ğŸ™ï¸</strong> and <strong>text-to-speech ğŸ”Š AI</strong> for hands-free interaction ğŸ’¬. </p> <p> Fully offline, it ensures <strong>privacy ğŸ”’</strong>, <strong>speed âš¡</strong>, and <strong>customizability</strong>, supporting both voice and text input/output ğŸ“±. </p> </td> <td style="width: 220px; text-align: center; vertical-align: top; padding: 40px;"> <img src="support.png" width="220" alt="Support" /> </td> </tr> </table> <!-- Row 3: Implement the Outcome --> <table style="width: 100%; border-collapse: collapse; font-family: sans-serif;"> <tr> <td style="width: 220px; text-align: center; vertical-align: top; padding: 40px;"> <img src="empower.png" width="220" alt="Empower" /> </td> <td style="padding: 40px; vertical-align: top;"> <h2 style="color: #dc2626; display: flex; align-items: center; gap: 10px; margin-top: 0;"> <span style="font-size: 24px;">âœ…</span> 3. Implement the Outcome </h2> <p> A fully functional, <strong>AI-driven tutoring system ğŸš€</strong> that runs locally on any device ğŸ“±. Students learn at their own pace using <strong>voice commands ğŸ™ï¸</strong> or <strong>chat input ğŸ’¬</strong>. </p> <p> Built with <strong>on-device AI</strong>, it supports diverse learners â™¿â€”ideal for those with disabilities or limited digital access. An empowering, joyful step forward in education ğŸ‰. </p> </td> </tr> </table>

**ğŸ’¬ Interactive** â€¢ **ğŸ“± Cross-Platform** â€¢ **â™¿ Accessible** â€¢ **ğŸš€ Performance** â€¢ **ğŸ‰ Engaging**

</div>

---

## ğŸŒŸ Overview

> **Why KinAI-Mentor?** While tech giants focus on enterprise solutions, we're addressing a fundamental need: helping students learn effectively when traditional support isn't available.

**KinAI-Mentor** isn't just another educational appâ€”it's a revolutionary **offline, voice-driven tutor** that brings personalized AI education to every student, regardless of their circumstances.

### ğŸ¯ Key Differentiators

- **ğŸ†“ Completely Free** - No subscriptions, no hidden costs, no data collection
- **ğŸ”§ Fully Open Source** - Hackable, customizable, and community-driven
- **ğŸ“š Curriculum-Aligned** - Based on Victorian Curriculum Fâ€“10 Version 2.0 syllabus
- **ğŸ¤ Multi-Modal Interface** - Voice, text, and visual interaction modes
- **ğŸŒ 100% Offline** - Works without internet connectivity
- **â™¿ Accessibility-First** - Designed for students with diverse needs

---

## â­ Key Features

<div align="center">

| Feature | Description | Technology |
|:--------|:------------|:-----------|
| **ğŸ¤ Voice Input** | Speak questions naturally | Advanced speech recognition |
| **ğŸ’¬ Text Chat** | Traditional typing interface | Streamlit UI components |
| **ğŸ—£ï¸ Voice Output** | Answers read aloud automatically | Local text-to-speech engine |
| **ğŸ“ƒ Visual Display** | Clear text responses on screen | Responsive web interface |
| **ğŸ“ Curriculum-Aligned** | Victorian Curriculum Fâ€“10 v2.0 compliant | Structured JSON database |
| **ğŸ’» Fully Offline** | No internet dependency | Local LLM processing |
| **ğŸ› ï¸ Open Source** | Free to modify and extend | MIT License |
| **ğŸŒ Multilingual Ready** | Expandable language support | Modular architecture |

</div>

---

## ğŸ—ï¸ System Architecture

```mermaid
graph TB
    subgraph "ğŸ¯ User Interaction Layer"
        A[ğŸ‘¤ Student] 
        A -->|ğŸ¤ Voice| B[ğŸ™ï¸ Microphone Input]
        A -->|ğŸ’¬ Text| C[âŒ¨ï¸ Text Input]
    end
    
    subgraph "ğŸ”„ Processing Engine"
        B --> D[ğŸ§ Speech-to-Text Processor]
        C --> E[âš™ï¸ Query Handler]
        D --> E
        E --> F[ğŸ¤– Ollama LLM Engine]
    end
    
    subgraph "ğŸ§  Knowledge Core"
        F <--> G[ğŸ’¾ General Knowledge Base]
        F <--> H[ğŸ“š Victorian Curriculum Fâ€“10 v2.0]
        F <--> I[ğŸ¯ Learning Analytics]
    end
    
    subgraph "ğŸ“¤ Response Generation"
        F --> J[ğŸ”§ Response Formatter]
        J --> K[ğŸ–¥ï¸ Text Display]
        J --> L[ğŸ”Š Text-to-Speech Engine]
        L --> M[ğŸ¶ Audio Output]
    end
    
    K --> A
    M --> A
```

### ğŸ“‹ Component Overview

| Component | Function | Implementation |
|-----------|----------|----------------|
| **ğŸ‘¤ User Interface** | Multi-modal input handling | Streamlit + Custom Components |
| **ğŸ§ Speech Processing** | Voice-to-text conversion | Offline speech recognition library |
| **ğŸ§  AI Engine** | Natural language processing | Ollama LLM (Llama 3) |
| **ğŸ’¾ Knowledge Base** | General educational content | Structured JSON database |
| **ğŸ“š Curriculum Engine** | Victorian Fâ€“10 v2.0 alignment | Curriculum-specific JSON |
| **ğŸ”Š Audio Output** | Text-to-speech synthesis | Local TTS engine |
| **ğŸ¯ Analytics** | Learning progress tracking | Local data storage |

---

## ğŸ¯ Why Choose KinAI-Mentor?

### ğŸŒŸ Educational Benefits

| Benefit | Impact | Target Users |
|:--------|:-------|:-------------|
| **â™¿ Universal Accessibility** | Supports visual, auditory, and motor disabilities | Students with diverse needs |
| **ğŸ§  Curriculum Alignment** | Structured learning based on Victorian Fâ€“10 v2.0 | Victorian students & educators |
| **ğŸ”„ Flexible Interaction** | Seamless voice â†” text switching | All learning preferences |
| **ğŸ“± Hands-Free Learning** | Perfect for multitasking students | Busy families & accessibility users |
| **ğŸ”’ Privacy Protection** | Zero data collection or tracking | Privacy-conscious families |
| **ğŸŒ Offline Capability** | Works in areas with poor connectivity | Rural & underserved communities |
| **ğŸ†“ Cost-Free Education** | No subscription or premium features | Low-income families |

### ğŸš€ Technical Advantages

- **âš¡ High Performance** - Local processing for instant responses
- **ğŸ”§ Fully Customizable** - Open source architecture for modifications
- **ğŸ“± Cross-Platform** - Works on Windows, macOS, and Linux
- **ğŸ›¡ï¸ Secure by Design** - No external data transmission
- **ğŸ“ˆ Scalable** - Easy to extend with new subjects or languages

---

## ğŸ› ï¸ Quick Start Guide

### ğŸ“‹ System Requirements

| Component | Minimum | Recommended | Purpose |
|:----------|:--------|:------------|:--------|
| **ğŸ Python** | 3.8+ | 3.11+ | Core runtime environment |
| **ğŸ¤– Ollama** | Latest | Latest | Local LLM processing |
| **ğŸ’¾ RAM** | 8GB | 16GB+ | AI model performance |
| **ğŸ’¿ Storage** | 10GB | 20GB+ | Models and data |
| **ğŸ¤ Microphone** | Any USB/Built-in | High-quality | Voice input |
| **ğŸ”Š Speakers/Headphones** | Any | Good quality | Audio output |

### âš¡ Installation Steps

```bash
# 1ï¸âƒ£ Clone the repository
git clone https://github.com/Logulokesh/kinai-mentor.git
cd kinai-mentor

# 2ï¸âƒ£ Create and activate virtual environment
python3 -m venv kinai-env
source kinai-env/bin/activate  # Windows: kinai-env\Scripts\activate

# 3ï¸âƒ£ Install Python dependencies
pip install -r requirements.txt

# 4ï¸âƒ£ Install and setup Ollama
# Download from https://ollama.ai and install
ollama pull llama3

# 5ï¸âƒ£ Verify installation
python -c "import streamlit; print('âœ… Streamlit ready')"
ollama list  # Should show llama3 model

# 6ï¸âƒ£ Launch KinAI-Mentor
streamlit run ui.py
```

### ğŸš€ Launch Commands

```bash
# Terminal 1: Start Ollama server
ollama serve

# Terminal 2: Run the AI model
ollama run llama3

# Terminal 3: Launch KinAI-Mentor interface
streamlit run ui.py
```

### ğŸ”§ Configuration Options

```python
# config.py - Customize these settings
OLLAMA_MODEL = "llama3"  # Change AI model
VOICE_ENABLED = True     # Enable/disable voice features
TTS_SPEED = 1.0         # Adjust speech speed
CURRICULUM_VERSION = "VIC_F10_V2"  # Curriculum alignment
```

---

## ğŸ“ Project Structure

```
kinai-mentor/
â”œâ”€â”€ ğŸ“„ README.md              # Project documentation
â”œâ”€â”€ ğŸ“‹ requirements.txt       # Python dependencies
â”œâ”€â”€ âš™ï¸ core_tutor.py         # Core AI logic & processing
â”œâ”€â”€ ğŸ–¥ï¸ ui.py                 # Streamlit user interface
â”œâ”€â”€ ğŸ“š syllabus.json         # Victorian Curriculum Fâ€“10 v2.0 data
â”œâ”€â”€ ğŸ“‚ voicetutor_db.json    # General knowledge base
â”œâ”€â”€ ğŸ”§ config.py             # Configuration settings
â”œâ”€â”€ ğŸ¨ assets/               # Images and media
â”œâ”€â”€ ğŸ“Š data/                 # Curriculum and learning data
â”œâ”€â”€ ğŸ§ª tests/               # Unit tests
â””â”€â”€ ğŸ“– docs/                # Additional documentation
```

### ğŸ“„ File Descriptions

| File | Purpose | Importance |
|:-----|:--------|:-----------|
| `core_tutor.py` | AI logic and response generation | ğŸ”´ Critical |
| `ui.py` | User interface and interaction | ğŸ”´ Critical |
| `syllabus.json` | Victorian Curriculum Fâ€“10 v2.0 structure | ğŸŸ¡ Important |
| `voicetutor_db.json` | General knowledge database | ğŸŸ¡ Important |
| `requirements.txt` | Python package dependencies | ğŸ”´ Critical |

---

## ğŸ› ï¸ Technology Stack

### ğŸ”§ Core Technologies

<div align="center">

[![Python](https://img.shields.io/badge/Python_3.11-FFD43B?style=for-the-badge&logo=python&logoColor=blue)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit_1.28-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)](https://streamlit.io)
[![Ollama](https://img.shields.io/badge/Ollama_LLM-000000?style=for-the-badge&logo=ollama&logoColor=white)](https://ollama.ai)

</div>

### ğŸ¤– AI & Audio Processing

<div align="center">

![Speech Recognition](https://img.shields.io/badge/SpeechRecognition-00D4AA?style=for-the-badge&logo=google&logoColor=white)
![Text to Speech](https://img.shields.io/badge/pyttsx3_TTS-4285F4?style=for-the-badge&logo=google&logoColor=white)
![JSON](https://img.shields.io/badge/JSON_Database-000000?style=for-the-badge&logo=json&logoColor=white)

</div>

### ğŸ“š Curriculum Integration

- **Victorian Curriculum Fâ€“10 Version 2.0** - Complete syllabus alignment
- **Subject Areas** - Mathematics, English, Science, Humanities
- **Learning Progressions** - Foundation to Year 10 coverage
- **Assessment Standards** - Achievement level mapping

---

## ğŸ“ Educational Alignment

### ğŸ“š Victorian Curriculum Fâ€“10 Version 2.0 Integration

KinAI-Mentor is specifically designed to support the **Victorian Curriculum Fâ€“10 Version 2.0**, ensuring students receive curriculum-compliant educational assistance.

#### ğŸ¯ Covered Learning Areas

| Learning Area | Year Levels | Key Features |
|:--------------|:------------|:-------------|
| **ğŸ“ English** | F-10 | Reading, writing, speaking, listening |
| **ğŸ”¢ Mathematics** | F-10 | Number, algebra, geometry, statistics |
| **ğŸ”¬ Science** | F-10 | Biological, chemical, physical, earth sciences |
| **ğŸŒ Humanities** | F-10 | History, geography, civics, economics |
| **ğŸ¨ The Arts** | F-10 | Visual arts, music, drama, dance |
| **ğŸ’ª Health & PE** | F-10 | Personal health, physical activity |
| **ğŸ’» Technologies** | F-10 | Digital technologies, design thinking |
| **ğŸ—£ï¸ Languages** | F-10 | Expandable language support |

#### ğŸ¯ Learning Progression Support

- **Foundation Level** - Early childhood learning foundations
- **Years 1-2** - Basic literacy and numeracy development
- **Years 3-4** - Skill building and concept introduction
- **Years 5-6** - Knowledge consolidation and application
- **Years 7-8** - Advanced concept exploration
- **Years 9-10** - Senior preparation and specialization

---

## ğŸ“¸ Screenshots & Demo

<div align="center">

### ğŸ–¥ï¸ Main Interface
*Clean, intuitive design optimized for learning*

![KinAI-Mentor Main Interface](https://raw.githubusercontent.com/Logulokesh/VICTutorAI-Offline-Educational-Assistant-Voice/refs/heads/main/screenshots/001%20-%20VoiceTutor%20Online%20Classroom%20-%20%5Blocalhost%5D.png)

---

### ğŸ’¬ Interactive Learning Session
*Real-time AI tutoring in action*

![Interactive Learning](https://raw.githubusercontent.com/Logulokesh/VICTutorAI-Offline-Educational-Assistant-Voice/refs/heads/main/screenshots/002%20-%20VoiceTutor%20Online%20Classroom%20-%20%5Blocalhost%5D.png)

---

### ğŸ¤ Voice Interaction Mode
*Hands-free learning experience*

![Voice Interaction](https://raw.githubusercontent.com/Logulokesh/VICTutorAI-Offline-Educational-Assistant-Voice/refs/heads/main/screenshots/003%20-%20VoiceTutor%20Online%20Classroom%20-%20%5Blocalhost%5D.png)

</div>

---

## ğŸ¤ Contributing to KinAI-Mentor

<div align="center">

**ğŸŒŸ Help us democratize education through AI! ğŸŒŸ**

[![Contribute](https://img.shields.io/badge/Contributions-Welcome-brightgreen?style=for-the-badge&logo=github)](CONTRIBUTING.md)
[![Issues](https://img.shields.io/badge/Report_Issues-Open-red?style=for-the-badge&logo=github)](https://github.com/Logulokesh/kinai-mentor/issues)
[![Pull Requests](https://img.shields.io/badge/Pull_Requests-Welcome-blue?style=for-the-badge&logo=github)](https://github.com/Logulokesh/kinai-mentor/pulls)

</div>

### ğŸ”§ How to Contribute

1. **ğŸ´ Fork** the repository on GitHub
2. **ğŸŒ¿ Create** a feature branch: `git checkout -b feature/amazing-improvement`
3. **ğŸ’» Make** your changes with clear, commented code
4. **âœ… Test** your changes thoroughly
5. **ğŸ“ Document** new features or changes
6. **âœ‰ï¸ Commit** with descriptive messages: `git commit -m 'Add voice speed control'`
7. **ğŸš€ Push** to your branch: `git push origin feature/amazing-improvement`
8. **ğŸ“¬ Submit** a Pull Request with detailed description

### ğŸ¯ Contribution Areas

- **ğŸ§  AI Model Integration** - Add new LLM support
- **ğŸ¤ Voice Processing** - Improve speech recognition
- **ğŸ“š Curriculum Expansion** - Add more subjects/regions  
- **â™¿ Accessibility Features** - Enhance inclusive design
- **ğŸŒ Internationalization** - Add language support
- **ğŸ¨ UI/UX Improvements** - Better user experience
- **ğŸ“± Mobile Optimization** - Responsive design
- **ğŸ§ª Testing & QA** - Improve reliability
- **ğŸ“– Documentation** - Better guides and tutorials

---

## ğŸ“œ License & Legal

<div align="center">

[![MIT License](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)

**Free to use, modify, and distribute under the MIT License**

</div>

### ğŸ”“ Open Source Freedom

- âœ… **Commercial Use** - Use in commercial projects
- âœ… **Modification** - Adapt to your needs
- âœ… **Distribution** - Share with others
- âœ… **Private Use** - Use internally
- âœ… **Patent Use** - No patent restrictions

### ğŸ“‹ Attribution Requirements

- Include original license text
- Credit original authors
- Note any modifications made

---

## ğŸ‰ Acknowledgments

### ğŸ™ Special Thanks

- **Victorian Curriculum Authority** - For curriculum standards
- **Ollama Team** - For local LLM technology
- **Streamlit Community** - For the amazing framework
- **Open Source Contributors** - For inspiration and code
- **Educators & Students** - For feedback and testing

---

<div align="center">

## ğŸŒŸ Join the Educational Revolution

**KinAI-Mentor** represents the future of personalized, accessible education. By combining cutting-edge AI with offline capabilities and curriculum alignment, we're creating learning opportunities for every student, regardless of their circumstances.

### ğŸš€ Get Started Today

```bash
git clone https://github.com/Logulokesh/kinai-mentor.git && cd kinai-mentor && pip install -r requirements.txt && streamlit run ui.py
```

---

<div align="center">

[![Contributors](https://contrib.rocks/image?repo=Logulokesh/KinAI-Ecosystem)](https://github.com/Logulokesh/KinAI-Ecosystem/graphs/contributors)

</div>

---

## ğŸ“„ License

Yes, itâ€™s completely free â€” just like a gesture of support ğŸ¤, a nod of appreciation ğŸ‘, or a reassuring smile ğŸ˜Š.

---

<div align="center">

**Built with passion â¤ï¸ for privacy, intelligence, and automation**

</div>
